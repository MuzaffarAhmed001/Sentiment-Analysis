{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_case_studies2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Final.ipynb file should contain the following :\n",
        "\n",
        "It should have two functions.\n",
        "\n",
        "Function-1\n",
        "\n",
        "Should include entire pipeline, from data preprocessing to making final predictions.\n",
        "\n",
        "It should take in raw data as input.\n",
        "\n",
        "It should return predictions for your input. Here the input can be a single point or a set of points.\n",
        "\n",
        "def final_fun_1(X):\n",
        "\n",
        ".....\n",
        "\n",
        "..... # you will use the best model that you found out with your experiments\n",
        "return predictions made on X ( Raw Data)\n",
        "\n",
        "Function-2\n",
        "\n",
        "Should include entire pipeline, from data preprocessing to making final predictions.\n",
        "\n",
        "It should take in raw data as input along with its target values.\n",
        "\n",
        "It should return the metric value that you are judging your models on.\n",
        "\n",
        "def final_fun_2(X,Y):\n",
        ".....\n",
        "\n",
        "..... # you will use the best model that you found out with your experiments\n",
        "return final_metric computed on X ( Raw Data) and Y (target variable)"
      ],
      "metadata": {
        "id": "uq2jZ4xd1bZa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importing Libraries\n"
      ],
      "metadata": {
        "id": "ba1OpUg-1Vh1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8DvGnGrw1Pbe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "import pickle\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from bs4 import BeautifulSoup\n",
        "import pickle\n",
        "from scipy.sparse import hstack\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score, f1_score,roc_curve,log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function1"
      ],
      "metadata": {
        "id": "wjyg8wLf2POL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/LSTM/featured_data','rb') as f:\n",
        "  data=pickle.load(f)\n",
        "X=data.drop('score',axis=1)\n",
        "y=data['score']"
      ],
      "metadata": {
        "id": "G_kGqmXUhw7e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase\n",
        "\n",
        "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
        "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
        "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
        "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
        "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
        "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
        "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
        "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
        "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
        "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
        "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
        "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
        "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
        "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
        "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
        "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "def preprocess_text(text_data):\n",
        "    #stemmer=SnowballStemmer(language=\"english\")\n",
        "    preprocessed_text = []\n",
        "    # tqdm is for printing the status bar\n",
        "    for sentance in text_data:\n",
        "        sentance = re.sub(r\"http\\S+\", \"\", sentance)\n",
        "        sentance = BeautifulSoup(sentance, 'lxml').get_text()\n",
        "        sentance = re.sub(\"\\S*\\d\\S*\", \"\", sentance).strip()\n",
        "        sent = decontracted(sentance)\n",
        "        sent = sent.replace('\\\\r', ' ')\n",
        "        sent = sent.replace('\\\\n', ' ')\n",
        "        sent = sent.replace('\\\\\"', ' ')\n",
        "        sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "        # https://gist.github.com/sebleier/554280\n",
        "        sent = ' '.join(e for e in sent.split() if e.lower() not in stopwords)\n",
        "        sent=sent.lower().strip()\n",
        "        #sent=\" \".join(stemmer.stem(e) for e in sent.split())\n",
        "        preprocessed_text.append(sent)\n",
        "    return preprocessed_text\n"
      ],
      "metadata": {
        "id": "sZ_jECrKRcFH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_func_1(X):\n",
        "  \"\"\"This function will preprocess all  data and \n",
        "  return prediction for a individual point\n",
        "  X: individual point\n",
        "  \"\"\"\n",
        "  #Dropping all the features which are having low variance and zero variance\n",
        "  file=open('/content/drive/MyDrive/LSTM/drop_features','rb')\n",
        "  drop_column=pickle.load(file)\n",
        "  file.close()\n",
        "  X.drop(drop_column,axis=1,inplace=True)\n",
        "  X['Review']=X['ReviewTitle']+\" \"+X['CompleteReview']\n",
        "  X.drop(['ReviewTitle','CompleteReview'],axis=1,inplace=True)\n",
        "  X[\"process_review\"]=preprocess_text(X[\"Review\"].values)\n",
        "  X.drop('Review',axis=1,inplace=True)\n",
        "  with open('/content/drive/MyDrive/LSTM/vectorizer','rb') as f:\n",
        "    vectorizer=pickle.load(f)\n",
        "  X_bow=vectorizer.transform(X['process_review'].values)\n",
        "  X_bow1 = hstack((X_bow,X.drop('process_review',axis=1).values)).tocsr()\n",
        "  model=load_model('/content/drive/MyDrive/LSTM/weights-22-0.9548.hdf5')\n",
        "  y_pred=model.predict(X_bow1)\n",
        "  if y_pred>=0.5:\n",
        "    y_class=1\n",
        "  else:\n",
        "    y_class=0\n",
        "  return y_class\n",
        "\n"
      ],
      "metadata": {
        "id": "I3NdFd5v2Q7K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now test this function with some Data points"
      ],
      "metadata": {
        "id": "_P_dj9xj152s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[[0]]['ReviewTitle'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J_8qnhW09bS",
        "outputId": "9d414f84-3dcb-4004-9a18-4ce881ed10d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Good Company for Every employee'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[[0]]['CompleteReview'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMCpxHFq2Fe8",
        "outputId": "96980ecc-91f6-4f79-e6e7-5f03db29956f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Good company for every Engineers dream, Full Mediclaim for entired family, Free transport services from company location to home, Township culture for employees,job security.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The above review is positive. Lets test this review with our model and predict the results**"
      ],
      "metadata": {
        "id": "pnnO8S1z2NiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=X.loc[[0]]\n",
        "y_pred=final_func_1(x)\n",
        "print(\"The Class of the given review is \",y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqnoHnCR0zCX",
        "outputId": "4459ab39-32bd-4eac-eb19-9be3190363b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Class of the given review is  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our model predicted correctly** "
      ],
      "metadata": {
        "id": "CpC8IO-C28Vy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Now let's look at negative review*"
      ],
      "metadata": {
        "id": "1D400dvs2pV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[[4]]['ReviewTitle'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvDMqTiX1AfI",
        "outputId": "b0e9c045-28a0-44d5-ce29-675fa6c957db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Not good'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.loc[[4]]['CompleteReview'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU41FUxB1oyw",
        "outputId": "53b87750-5e57-442c-bce9-eab7ca2f5768"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Work culture not good and no benefits. I would recommend anyone to join Mphasis atleast not in India. There is no growth in career and salary is too low. Also the HR are no help at all'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now lets this review with our model**"
      ],
      "metadata": {
        "id": "zngUT7ef21-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=X.loc[[4]]\n",
        "y_pred=final_func_1(x)\n",
        "print(\"The Class of the given review is \",y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7rILK8120vB",
        "outputId": "64aaa36e-10d1-439e-c769-cead355696f6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Class of the given review is  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our model predicted correctly** "
      ],
      "metadata": {
        "id": "lqTOaZmE3O4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function2"
      ],
      "metadata": {
        "id": "0MS235mp3RML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_func_2(X,y):\n",
        "  \"\"\"This function will preprocess all the data and \n",
        "  return Metric score(R-squared value) for a set of points\"\"\"\n",
        "   #Dropping all the features which are having low variance and zero variance\n",
        "  #Dropping all the features which are having low variance and zero variance\n",
        "  file=open('/content/drive/MyDrive/LSTM/drop_features','rb')\n",
        "  drop_column=pickle.load(file)\n",
        "  file.close()\n",
        "  X.drop(drop_column,axis=1,inplace=True)\n",
        "  X['Review']=X['ReviewTitle']+\" \"+X['CompleteReview']\n",
        "  X.drop(['ReviewTitle','CompleteReview'],axis=1,inplace=True)\n",
        "  X[\"process_review\"]=preprocess_text(X[\"Review\"].values)\n",
        "  X.drop('Review',axis=1,inplace=True)\n",
        "  with open('/content/drive/MyDrive/LSTM/vectorizer','rb') as f:\n",
        "    vectorizer=pickle.load(f)\n",
        "  X_bow=vectorizer.transform(X['process_review'].values)\n",
        "  X_bow1 = hstack((X_bow,X.drop('process_review',axis=1).values)).tocsr()\n",
        "  model=load_model('/content/drive/MyDrive/LSTM/weights-22-0.9548.hdf5')\n",
        "  y_pred=model.predict(X_bow1)\n",
        "  y_class=[]\n",
        "  for i in y_pred:\n",
        "    if i>=0.5:\n",
        "      y_class.append(1)\n",
        "    else:\n",
        "      y_class.append(0)\n",
        "  accuracy=accuracy_score(y,y_class)\n",
        "  f1_score_model=f1_score(y,y_class)\n",
        "  auc=roc_auc_score(y,y_class)\n",
        "  logloss=log_loss(y,y_class)\n",
        "  return {\"accuracy\":accuracy,\"f1_score\":f1_score_model,\"Auc_score\":auc,\"log_loss\":logloss}\n"
      ],
      "metadata": {
        "id": "_AqP29B93K9a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's check the metrics for the whole data**"
      ],
      "metadata": {
        "id": "MCdBYOL4Lf7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_func_2(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TNzbEf2LC__",
        "outputId": "e438fb73-e4c1-44cc-bcfe-4a0ae4ac8d9a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Auc_score': 0.7180968349750804,\n",
              " 'accuracy': 0.9575730003875381,\n",
              " 'f1_score': 0.9776636417666835,\n",
              " 'log_loss': 1.46540593586075}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy achieved is 95.75%, auc_score is 0.72, f1_score is 0.97 and log_loss is 1.46**"
      ],
      "metadata": {
        "id": "PRmxvNi_LeJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nLocvcagLzCn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}